{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Literal, Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6253c2c750>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def ask_more_details(query: str) -> str:\n",
    "  \"\"\"\n",
    "    Peça por mais informações para o usuário\n",
    "  \"\"\"\n",
    "  print(f\"ASK_MORE_DETAILS -> {query}\")\n",
    "  human_response = interrupt({\"query\": query})\n",
    "  return human_response[\"data\"]\n",
    "\n",
    "tools = [ask_more_details]\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6253c2c750>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_receptionist = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "receptionist_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"Você é um assistente de compras online, responsavel por atender o usuário, perguntando o que ele deseja comprar.\"),\n",
    "  MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "def receptionist(state: State):\n",
    "  print(\"RECEPTIONIST\")\n",
    "  message = (receptionist_prompt | llm_receptionist.bind_tools(tools)).invoke(state[\"messages\"])\n",
    "  assert len(message.tool_calls) <= 1\n",
    "  return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"receptionist\", receptionist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6253c2c750>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_analyst = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"Você é um assistente de compras online, responsavel analisar produtos e selecionar os mais relevantes de acordo com os dados recebidos.\"),\n",
    "  MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "def analyst(state: State):\n",
    "  print(\"ANALYST\")\n",
    "  return {\"messages\": [llm_analyst.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"analyst\", receptionist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6253c2c750>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_product_reviewer = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "product_reviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"Você é um assistente de compras online, responsavel por comparar produtos pré-selecionados afim de ajudar o usuário na sua decisão de compra.\"),\n",
    "  MessagesPlaceholder(\"messages\")\n",
    "])\n",
    "\n",
    "def product_reviewer(state: State):\n",
    "  print(\"PRODUCT_REVIEWER\")\n",
    "  return {\"messages\": [llm_product_reviewer.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"product_reviewer\", receptionist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f6253c2c750>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def need_more_details(state: State) -> Literal[\"tools\", \"analyst\"]:\n",
    "  \"\"\"Define se precisa pedir mais detalhes para o usuário\"\"\"\n",
    "  print(\"NEED_MORE_DETAILS\")\n",
    "  last_message = state[\"messages\"][-1]\n",
    "  return \"tools\" if last_message.tool_calls else \"analyst\"\n",
    "\n",
    "\n",
    "graph_builder.add_edge(START, \"receptionist\")\n",
    "graph_builder.add_conditional_edges(\n",
    "  \"receptionist\",\n",
    "  need_more_details,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"receptionist\")\n",
    "graph_builder.add_edge(\"analyst\",  \"product_reviewer\")\n",
    "graph_builder.add_edge(\"product_reviewer\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "  # This requires some extra dependencies and is optional\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECEPTIONIST\n",
      "NEED_MORE_DETAILS\n",
      "Assistant: \n",
      "ASK_MORE_DETAILS -> Que tipo de tênis você está procurando? (ex: esportivo, casual, para correr, etc.)\n",
      "User: What do you know about LangGraph?\n",
      "RECEPTIONIST\n",
      "NEED_MORE_DETAILS\n",
      "Assistant: LangGraph is a platform that often combines elements of language processing and graph databases to facilitate various applications, including natural language understanding and relationship mapping. It allows users to leverage language models and graph structures to analyze, visualize, and extract insights from textual data.\n",
      "\n",
      "The details and capabilities of LangGraph can vary depending on its implementations and updates. If you are looking for specific functionalities or use cases, please let me know!\n",
      "RECEPTIONIST\n",
      "Assistant: \n",
      "RECEPTIONIST\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_fV87rTdQmItZuwCyXA4pF2NN\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you know about LangGraph?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m user_input)\n\u001b[0;32m---> 19\u001b[0m stream_graph_updates(user_input)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[187], line 2\u001b[0m, in \u001b[0;36mstream_graph_updates\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream_graph_updates\u001b[39m(user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input}]}):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      4\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2031\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2025\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2027\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2031\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2032\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2033\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2034\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2035\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2036\u001b[0m         ):\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2038\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     run_with_retry(\n\u001b[1;32m    231\u001b[0m         t,\n\u001b[1;32m    232\u001b[0m         retry_policy,\n\u001b[1;32m    233\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    234\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[1;32m    235\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[1;32m    236\u001b[0m         },\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langgraph/utils/runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[181], line 10\u001b[0m, in \u001b[0;36mreceptionist\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreceptionist\u001b[39m(state: State):\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRECEPTIONIST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m   message \u001b[38;5;241m=\u001b[39m (receptionist_prompt \u001b[38;5;241m|\u001b[39m llm_receptionist\u001b[38;5;241m.\u001b[39mbind_tools(tools))\u001b[38;5;241m.\u001b[39minvoke(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(message\u001b[38;5;241m.\u001b[39mtool_calls) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [message]}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m   5361\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5363\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5364\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    285\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    691\u001b[0m                 m,\n\u001b[1;32m    692\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    693\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    694\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    695\u001b[0m             )\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    926\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    927\u001b[0m         )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:790\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 790\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    881\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    882\u001b[0m             {\n\u001b[1;32m    883\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    884\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    885\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m    886\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    887\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    888\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    889\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    890\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    891\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    892\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    893\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    894\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m    895\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    896\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    897\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m    898\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    899\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    900\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    901\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    902\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    903\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    904\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    906\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    907\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    908\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    909\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    910\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    911\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    912\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    913\u001b[0m             },\n\u001b[1;32m    914\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    915\u001b[0m         ),\n\u001b[1;32m    916\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    917\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    918\u001b[0m         ),\n\u001b[1;32m    919\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    920\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    921\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    922\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1296\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1284\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1292\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1293\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1294\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1295\u001b[0m     )\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    971\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    974\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    975\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    976\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    977\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    978\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    979\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1077\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1076\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1077\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1080\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1081\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1086\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_fV87rTdQmItZuwCyXA4pF2NN\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "  for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "    for value in event.values():\n",
    "      print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "      print(\"Goodbye!\")\n",
    "      break\n",
    "\n",
    "    stream_graph_updates(user_input)\n",
    "  except:\n",
    "    # fallback if input() is not available\n",
    "    user_input = \"What do you know about LangGraph?\"\n",
    "    print(\"User: \" + user_input)\n",
    "    stream_graph_updates(user_input)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
